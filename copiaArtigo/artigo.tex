\documentclass[sigconf]{acmart}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}


\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%%

\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
June 03--05, 2018, Woodstock, NY}

\acmISBN{978-1-4503-XXXX-X/2018/06}

%%\acmSubmissionID{123-A56-BU3}

\begin{document}


\title{Analysis of the Capability and Training of Chat Bots in the
Generation of Rules for Firewall or Intrusion Detection Systems}


\author{Bernardo Louro}
\institution{Univesidade da Beira Interior}
\affiliation{%
  \institution{Instituto de Telecomunicações}
  \city{Covilhã}
  \country{Portugal}
    \email{bernardo.louro@ubi.pt}
}

\author{Raquel Abreu}
\affiliation{%
    \institution{Univesidade da Beira Interior}
    \city{Covilhã}
    \country{Portugal}
    \email{raquel.filipa.abreu@ubi.pt}
}

\author{Joana C. Costa}
\institution{Univesidade da Beira Interior}
\affiliation{%
  \institution{Instituto de Telecomunicações}
  \city{Covilhã}
  \country{Portugal}
    \email{joana.cabral.costa@ubi.pt}
}

\author{João B. F. Sequeiros}
\institution{Univesidade da Beira Interior}
\affiliation{%
  \institution{Instituto de Telecomunicações}
  \city{Covilhã}
  \country{Portugal}
    \email{jbfs@ubi.pt}
}

\author{Pedro R. M. Inácio}
\institution{Univesidade da Beira Interior}
\affiliation{%
  \institution{Instituto de Telecomunicações}
  \city{Covilhã}
  \country{Portugal}
    \email{prmi@ubi.pt}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Louro et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
 Large Language Models (LLMs) have the potential to aid in closing
the knowledge gap in several specific technical areas, such as cybersecurity, by providing a means to translate instructions defined
in natural language into specialized system or software specifications ({\itshape e.g.}, firewall rules). The work described herein aims at an
evaluation of the capability of LLMs to generate rules for firewall
and Intrusion Detection Systems (IDSs). A preliminary assessment
has shown that widely available chat bots have limited capability
to generate correct rules and that caution is needed when using
their outputs for the aforementioned objective. This work explores
three fine-tuning approaches to address these limitations, each of
them with a different objective and achieving distinct success rates.
The first approach aimed at testing how well the model was able to
use the knowledge obtained from the prompts when the question
was structured differently, achieving a success rate of 89\%\. The
second approach aimed at testing how well the model could link
the knowledge obtained from two different prompts and reached
a success rate of 61\%\. The final approach aimed at testing if the
model could create complex rules by first learning simple rules,
achieving a success rate of 79\%\. It can be concluded that fine-tuning
is sufficient to improve chat bots into creating syntactically and
technically correct rules for firewalls and IDSs. Results suggest
that the development of a specialized model for as many attacks,
firewalls and IDSs can indeed be achieved.

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>00000000.0000000.0000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Firewalls, Intrusion Detection Systems, Large Language Models}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
  \includegraphics[width=\textwidth]{sampleteaser}
  \caption{Seattle Mariners at Spring Training, 2010.}
  \Description{Enjoying the baseball game from the third-base
  seats. Ichiro Suzuki preparing to bat.}
  \label{fig:teaser}
\end{teaserfigure}

\received{20 February 2007}
\received[revised]{12 March 2009}
\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
The recent advancements in Large Language Models (LLMs) have
brought renewed attention to Artificial Intelligence (AI). The text
generation capability of LLMs, publicly and easily accessible via
chatbots, finds many different application scenarios \cite{Kaddour23, Okonkwo21, Reis20}

and
shows potential to magnify human knowledge or aid in closing a
knowledge gap in several specific technical areas, namely in computer science where {\itshape e.g.}, it is currently used in code development
assistance (by over 92\%\ of U.S.-based developers) \cite{Shani23}.

. These models, which are capable of engaging in meaningful conversations
with humans, also might lead to the creation of erroneous or fictional information \cite{Chen23, Kabir23} whose consequences vary depending on
the use of the outputs and the application scenario. The work described herein aimed at (preliminarily) evaluating the capability of
LLMs, available in 2024, translating instructions defined in natural
language into rules for firewalls or Intrusion Detection Systems
(IDSs). The creation of such rules sometimes poses challenges even
for seasoned system administrators, as they are specific to a highly
technical and frequently changing area.
The fact that LLMs have undergone training on an extensive
range of Internet-available data allows them to understand and
respond to diverse queries and tasks. This includes the ability to
translate natural language into various programming languages,
scripts or configurations for cybersecurity tools. For instance, one
might ask a chat bot to generate an {\itshape iptables} rule to prevent a specific
cyberattack, providing only the name of the attack and relying on
the ability of the model to extrapolate the necessary information to
compose a relevant and effective rule. The chat bot will probably
produce a rule, as examples are found in specialized forums on
the Internet (and thus in the aforementioned datasets). The rule might even look syntactically correct, which makes it harder to
evaluate if it is appropriate or useful. Currently available LLMs did
not receive explicit training on cybersecurity, let alone specifically
in the generation of firewall and IDS rules and their responses
may not always align with the intended security goals. The risk
of generating erroneous or suboptimal rules raises concerns about
the reliability of using such models in practical security settings.
Initially motivated by these doubts, a (human) analysis was conducted, to explore how well the available chat bots are able to write
firewall and IDS rules and then followed up with a look into the
possibility of fine-tuning these language models for this specific
task. This work was conducted resorting to easily available LLMs
and open-source tools or systems. For example, {\itshape iptables} \cite{Russsell98} and {\itshape Snort} \cite{Shaqiri21} were chosen as the target firewall and IDS.
The main contributions of this work can be summarised as follows:
\begin{itemize}
\item A study (and conclusions) of the capacity of currently available chat bots to generate firewall and IDS rules;
\item Increasing awareness on the use of chat bots for automated
generation of security settings, and on how these can provide erroneous information, and should be relied upon with
utmost care and always under supervision;
\item A dataset containing a collection of prompts describing attacks and the corresponding rules for {\itshape iptables} and {\itshape Snort};
\item An analysis of different approaches to fine-tuning with comparisons and conclusions;
\item An analysis of the difference between pre-tuned and finetuned models with comparisons and conclusions.
\end{itemize}
The remainder of this paper is structured as follows: section 2
elaborates on related works and background; section 3 delves into
the analysis of the capability of current chat bots, the methodology used and some of its conclusions, and the fine-tuning method
and approaches that will be used; section 4 looks into the results
obtained from the fine-tuning, the conclusions drawn and comparisons between pre-tuned and fine-tuned models; finally, section 5
presents the conclusions and future work.


\section{RELATED WORKS AND BACKGROUND}
The use of chat bots in different technical fields has become a focus
of interest recently, namely in cybersecurity. The use of chat bots for
writing and defining firewall and IDS rules, as approached herein, is
a specific application in this broader field. While no specific equivalent approaches have been found in the literature, SecBot \cite{Franco20, Shaqiri21}
shows relatable inspiration, though following a different approach
and with different (yet relatable) final objectives. Fine-tuning techniques have also been analysed and used to customize chat bots
in different fields, showing the validity of this approach to improve their applicability in specific areas. This section identifies
and explores several works that reflect the research in this area,
highlighting the opportunities these novel approaches bring.

This document will explain the major features of the document
class. For further information, the {\itshape \LaTeX\ User's Guide} is
available from
\url{https://www.acm.org/publications/proceedings-template}.

\subsection{SecBot}

{\itshape SecBot}  \cite{Franco20, Shaqiri21}  is a chat bot that aims to aid businesses through
support in cybersecurity planning and management. It identifies cyberattacks based on related symptoms, and indicates solutions and
configurations according to business demands, providing insightful information for the investments and risks that come with certain decisions regarding cybersecurity. {\itshape SecBot}, as a language model, is fed
with information specific to the business, such as budget, and also
specific terms or values that it may need for its analysis, requesting
information that could not be ascertained from the initial prompt.
After the information retrieval stage and starting from a list of
attacks, the chat bot recommends a solution based on the requests
of the user and the performed business analysis. This recommendation is achieved by following pre-written rules, using language
processing to extract the required information, and defining the
solution to be outputted. {\itshape SecBot} has a similar philosophy with that
of this work, {\itshape i.e.}, its purpose is to output recommendations in the
cybersecurity field, but differs in being business oriented, and being
purpose built, with its rules already defined in its construction.

\subsection{Fine-tuning Chat Bots}

Fine-tuning is a type of technique that provides an LLM with a set
of specific prompts and example responses, with the final purpose
of improving the output capabilities of the model for that specific
subset of knowledge. The work described in \cite{Peng23} uses the Generative Pre-trained Transformer (GPT)-4 to generate responses to 52
000 instructions, to then perform the same procedure again but
in Chinese, by translating the instructions and having ChatGPT-4
answer them in Chinese also. This procedure was used to generate
datasets to fine-tune other models (in this case, LLaMA 7B). The
fine-tuned version of LLaMA 7B showed a strong improvement
in performance, validating the use of fine-tuning. \cite{Bill23} used reinforcement learning from human feedback for a therapy chat bot, by
using interactions between therapists and clients to fine-tune the
model. No significant differences were seen between the pre-trained
model and the fine-tuned one, attributed by the authors to the low
amount of data used, a limitation to be further explored in future
work. This shows that, while fine-tuning is a valid approach to improve the output of LLMs, it is not a guaranteed success, requiring
a well-constructed dataset to achieve the objective of improving
the outputs of the model for the specific field.

\subsection{Chat Bots in Other Security Settings}
The use of chat bots in cybersecurity-specific areas, such as data
protection, privacy, and other social aspects, and the concerns about
cybersecurity due to their use, have been a topic of discussion in
several works. Data protection and privacy are important aspects
when considering the use of chat bots and LLMs \cite{Sebastian23} for several
reasons, namely ethical considerations (the personal data of users
should not be shared, and any bias should be avoided), building user
trust, maintaining data integrity, and reducing the risk of adverse
attacks.
There are also privacy risks and data leakage concerns \cite{Hasal21}, namely
the unintentional sharing of sensitive information during transmission and data poisoning, factors that can influence the behavior
of the model. Finally, there are recommendations to mitigate privacy risks and strengthen data protection, which can include data
anonymization, the use of privacy-aware machine learning algorithms, adversarial training, robust training (for example, using
contradictory examples to improve the model, and testing how
the model handles these unusual or unexpected examples), data verification, limiting the rate of requests, and the use of encryption.
In addition to these studies, the work in \cite{Bozic18} focused on testing
and analyzing how vulnerable a chat bot is to hackers. For this
purpose, a framework was created to test whether or not chat bots
are vulnerable to Cross-Site Scripting (XSS) and Structured Query
Language (SQL) injections, and the results obtained were positive,
as they provided evidence that the chat bot used was resistant to
these common attacks.
The authors of \cite{Hilario24} approached using ChatGPT in pen-testing,
showing the benefits, challenges, risks and consequences of integrating generative AI tools into traditional pen-testing frameworks.
The benefits mentioned include improved efficiency and continuous
learning, while the risks and consequences include overreliance
and ethical, legal, and bias concerns. The work in \cite{Temara23} also explored
pen-testing using ChatGPT, and it focused specifically on the recognition phase, concluding that it is a valuable tool, as it provides
insightful information. In addition, it is worth noting that the way
the prompt is written affects the response given by the chat bot,
something to consider when creating a set of prompts, either for
receiving answers from the model or to create, {\itshape e.g.}, a dataset for
fine-tuning a model. Qammar {\itshape et al.} \cite{Qammar23} investigated the capability
of ChatGPT to generate malicious code or messages to produce
attacks against common systems/users ({\itshape e.g.}, generate phishing emails). The authors concluded that ChatGPT can successfully create
malicious code and messages, highlighting the capacity to produce
undetectable zero-day attacks.
Chat bots and LLMs can either be useful tools for cybersecurity,
the cause of cybersecurity issues, or recipients of analysis and
information security techniques (to make them robust to attacks).
This section highlights the potential to use LLMs for the purpose
described herein, as they were used in similar contexts for other
objectives. Nonetheless, the usefulness of these models and chat
bots needs to be carefully considered in light of potential issues that
might arise from misuse or incorrect outputs, partially motivating
the work presented herein.
the dataset, the instructions to replicate the experiments are also
included therein. The attacks were used to write prompts for the
chat bots, and an analysis of how they responded to the different prompts was conducted, and are described in the subsequent
sections.

\subsubsection{{\itshape  Identifying Cyberattacks and Rules.}}
A total of thirty cyberattacks were identified, and the corresponding efficient and correct
{\itshape iptables} and {\itshape Snort} rules were crafted or collected from the official
documentation. The majority of the identified attacks are Denial
of Service (DoS) or Distributed Denial of Service (DDoS) attacks,
including, but not limited to, floods ({\itshape e.g.}, UDP flooding) and low
and slow attacks ({\itshape e.g.}, Slowloris). Other attacks include buffer and
integer overflow exploits, MySQL/SQL injections, shellcode exploits
and XSS.

\subsubsection{{\itshape Writing Prompts for each Cyberattack}}

Motivated by one of the previously mentioned works \cite{Temara23},  and by the need to understand
how differently crafted prompts could affect the responses given
by the chat bots, a total of three different prompts were written
for each cyberattack. These three different prompts are intended
to exemplify how people with different levels of knowledge may
request the chat bot to create a rule for a cyberattack.
The first type of prompt concerns a simple prompt with just the
name of the attack (without any specific technical details), which is
expected from a person with no knowledge of the subject, and who
has only researched the most common attacks. The second type
of prompt explains the attack on a more technical level, which is
expected from people who understand the attack methodology but
do not know how to prevent it. The third type of prompt explicitly
states what the rule should do, {\itshape i.e.}, it gives the answer to solve
the problem, which is expected from people who know how to
avoid this type of attack and with basic knowledge on how to write
{\itshape iptables} and {\itshape Snort} rules. For example, the following represent the
three types of prompts for the Ping of Death attack:
\begin{itemize}
  \item First Prompt - {\itshape Write an iptables rule to avoid Ping of Death
attacks;}
\item Second Prompt - {\itshape Write an iptables rule that avoids an attack in
which the attacker sends a malformed ping packet that exceeds
the maximum IPv4 packet size;}
\item Third Prompt - {\itshape Write an iptables rule that drops ICMP packets
with a length greater than 65,535 bytes.}
\end{itemize}

\subsubsection{{\itshape Choosing Chat Bots.}}

After establishing the prompts, a set of chat bots were selected to test their responses to the different
queries, as to evaluate their capabilities, before any fine-tuning, in
terms of crafting the correct rules. The responses were manually
evaluated, checking the correctness of the created rules, both on a
syntactic and on a technical level.
The chosen chat bots were ChatGPT \cite{OpenAI22}, LLaMA \cite{Meta23}, Mistral
7B  \cite{Jiang23}, and GPT4All Falcon, Wizard v1.1 and Nous-Hermes  \cite{Anand23}. The first two were chosen due to their status as state-of-the-art chat
bots. ChatGPT 3.5 and LLaMA 2 7B were also selected, the first due
to it being the currently publicly available free version of ChatGPT,
and the latter due to hardware limitations. Mistral 7B was selected
due to outperforming LLaMA 2 13B in all the benchmarks where
it has been evaluated, and also outperforming LLaMA 1 34B in
code generation, among other aspects. The last three models were chosen due to being less Random Access Memory (RAM)-intensive
compared to the majority of available, high performing LLMs, a
potential bottleneck when running them locally and fine-tuning
them. Falcon only requires 8GB of RAM, with Wizard v1.1 and NousHermes requiring 16GB. As seen in the benchmarks published by
GPT4All \cite{Anand23}, these three models achieve some of the best results
in these memory-constrained scenarios, not taking into account
quantized models, {\itshape i.e.}, a technique that reduces computational and
memory costs by using weights and activations with low-precision
data types, such as 4-bit normalized float, instead of the usual 32-bit
float.

\subsubsection{{\itshape Rule Writing Capability}}

The following step was the evaluation of the chat bots and their capabilities in terms of generating the
expected outputs from the crafted prompts dataset. Table 1 shows
the achieved results for each of the tested models. The success rate
was calculated by humanly analysing the answers of the chat bots
to the prompts and considering as correct those answers that contained the correct and efficient rule for the corresponding attack.
ChatGPT 3.5 achieved the best results, with a success rate of 42\%\ ,
from a total of 53 correct answers out of the 126 questions. Though
the success rate appears low, the majority of fails were due to minor
deviations from the correct answer. LLaMA 2 7B failed all 126 questions, showing minimal knowledge of {\itshape iptables} and {\itshape Snort}. Mistral
7B model correctly answered a total of five out of the 126 questions and, compared to the LLaMA 2 7B, it showed overall stronger
knowledge of {\itshape iptables} and {\itshape Snort}. Of the 126 questions, GPT4All
Falcon succeeded only once, Nous-Hermes twice and Wizard v1.1
zero times, with the latter model showing very little knowledge
of {\itshape iptables}, and even less of {\itshape Snort}. It is probable that the superior
results obtained for ChatGPT are related to the potentially much
larger (and diverse) dataset with which it was trained.
The conclusion to be drawn from these results is that chat bots
do indeed give erroneous information, at least when generating
security-related instructions without being specifically trained. As
such, their answers should always be handled with caution. This
analysis intended to be used as a way of raising awareness to this
fact, and as a systematic study on the capacity of several currently
available chat bots, which will be studied in greater depth in the
next section.

\begin{tabularx}{0.8\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\centering\arraybackslash}X 
  | >{\raggedleft\arraybackslash}X | }
 \hline
{\bfseries Model & Correct Answers & Success Rate \\}

 ChatGPT 3.5 & 53 out of 126 & 42\% \\
 \hline
 LLaMA 2 7B  & 0 out of 126  & 0\%  \\
  \hline
 Mistral 7B   & 5 out of 126  & 4\%  \\
  \hline
 GPT4All Falcon  & 1 out of 126  & <1\%  \\
  \hline
 Nous-Hermes   & 2 out of 126  & simbolo aproximado 2\%  \\
  \hline
 Wizard  & 0 out of 126  & 0\%  \\
\hline
\end{tabularx}


\subsection{Analysis of Data Collection}

This subsection contains a detailed analysis of the achieved results
and related conclusions in regards to the capabilities of chat bots
to produce rules for {\itshape iptables} and {\itshape Snort}.

\subsubsection{{\itshape  Results for Different Types of Prompts.}}

In terms of success
rate, the third type of prompt was the one leading to better results,
which was expected and can be explained due to the fact that this
was the case where the prompt indirectly contained the expected
answer (even if in natural language), requiring the chat bot to
only convert it into the appropriate technical language (format) for
obtaining the rules. The only prompt that GPT4All Falcon model
got right was one of those prompts; one of the two rules that the
Nous-Hermes model got right was also a third type of prompt;
four of the five correct answers from Mistral 7B, and 37 of the 53
answers correctly given by ChatGPT 3.5 were also of the third type
of prompts. In total, of the 61 prompts that the models correctly
answered, 43 were of the third type of prompts, adding up to 70\%
of the correct answers. From these results, and from what was
observed during the analysis of the answers given by the chat bots,
it can be concluded that, when a chat bot has some knowledge of
the syntax used by the firewall or IDS, it can translate the solution
provided in natural language into a correct and efficient rule, but
it may not successfully induce the link between the name of the
attack or what the attack is doing to the correct solution.

\subsubsection{{\itshape  Results for Iptables and Snort}}

As previously mentioned, all
the chat bots showed at least some knowledge when it came to
writing {\itshape iptables} rules, but the same cannot be said for {\itshape Snort}, and the
results corroborate this conclusion: the Nous-Hermes and GPT4All
Falcon models only got {\itshape iptables} rules correctly; out of the five
correct answers from Mistral 7B, three were {\itshape iptables} rules; ChatGPT
3.5 correctly crafted approximately 58\% of the {\itshape iptables} rules, almost
double the percentage of correct answers for the {\itshape Snort} rules (33\%)

\subsection{Fine-tuning Method}




\section{Typefaces}

The ``\verb|acmart|'' document class requires the use of the
``Libertine'' typeface family. Your \TeX\ installation should include
this set of packages. Please do not substitute other typefaces. The
``\verb|lmodern|'' and ``\verb|ltimes|'' packages should not be used,
as they will override the built-in typeface families.

\section{Title Information}

The title of your work should use capital letters appropriately -
\url{https://capitalizemytitle.com/} has useful rules for
capitalization. Use the {\verb|title|} command to define the title of
your work. If your work has a subtitle, define it with the
{\verb|subtitle|} command.  Do not insert line breaks in your title.

If your title is lengthy, you must define a short version to be used
in the page headers, to prevent overlapping text. The \verb|title|
command has a ``short title'' parameter:
\begin{verbatim}
  \title[short title]{full title}
\end{verbatim}

\section{Authors and Affiliations}

Each author must be defined separately for accurate metadata
identification.  As an exception, multiple authors may share one
affiliation. Authors' names should not be abbreviated; use full first
names wherever possible. Include authors' e-mail addresses whenever
possible.

Grouping authors' names or e-mail addresses, or providing an ``e-mail
alias,'' as shown below, is not acceptable:
\begin{verbatim}
  \author{Brooke Aster, David Mehldau}
  \email{dave,judy,steve@university.edu}
  \email{firstname.lastname@phillips.org}
\end{verbatim}

The \verb|authornote| and \verb|authornotemark| commands allow a note
to apply to multiple authors --- for example, if the first two authors
of an article contributed equally to the work.

If your author list is lengthy, you must define a shortened version of
the list of authors to be used in the page headers, to prevent
overlapping text. The following command should be placed just after
the last \verb|\author{}| definition:
\begin{verbatim}
  \renewcommand{\shortauthors}{McCartney, et al.}
\end{verbatim}
Omitting this command will force the use of a concatenated list of all
of the authors' names, which may result in overlapping text in the
page headers.

The article template's documentation, available at
\url{https://www.acm.org/publications/proceedings-template}, has a
complete explanation of these commands and tips for their effective
use.

Note that authors' addresses are mandatory for journal articles.

\section{Rights Information}

Authors of any work published by ACM will need to complete a rights
form. Depending on the kind of work, and the rights management choice
made by the author, this may be copyright transfer, permission,
license, or an OA (open access) agreement.

Regardless of the rights management choice, the author will receive a
copy of the completed rights form once it has been submitted. This
form contains \LaTeX\ commands that must be copied into the source
document. When the document source is compiled, these commands and
their parameters add formatted text to several areas of the final
document:
\begin{itemize}
\item the ``ACM Reference Format'' text on the first page.
\item the ``rights management'' text on the first page.
\item the conference information in the page header(s).
\end{itemize}

Rights information is unique to the work; if you are preparing several
works for an event, make sure to use the correct set of commands with
each of the works.

The ACM Reference Format text is required for all articles over one
page in length, and is optional for one-page articles (abstracts).

\section{CCS Concepts and User-Defined Keywords}

Two elements of the ``acmart'' document class provide powerful
taxonomic tools for you to help readers find your work in an online
search.

The ACM Computing Classification System ---
\url{https://www.acm.org/publications/class-2012} --- is a set of
classifiers and concepts that describe the computing
discipline. Authors can select entries from this classification
system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
commands to be included in the \LaTeX\ source.

User-defined keywords are a comma-separated list of words and phrases
of the authors' choosing, providing a more flexible way of describing
the research being presented.

CCS concepts and user-defined keywords are required for for all
articles over two pages in length, and are optional for one- and
two-page articles (or abstracts).

\section{Sectioning Commands}

Your work should use standard \LaTeX\ sectioning commands:
\verb|\section|, \verb|\subsection|, \verb|\subsubsection|,
\verb|\paragraph|, and \verb|\subparagraph|. The sectioning levels up to
\verb|\subsubsection| should be numbered; do not remove the numbering
from the commands.

Simulating a sectioning command by setting the first word or words of
a paragraph in boldface or italicized text is {\bfseries not allowed.}

Below are examples of sectioning commands.

\subsection{Subsection}
\label{sec:subsection}

This is a subsection.

\subsubsection{Subsubsection}
\label{sec:subsubsection}

This is a subsubsection.

\paragraph{Paragraph}

This is a paragraph.

\subparagraph{Subparagraph}

This is a subparagraph.

\section{Tables}

The ``\verb|acmart|'' document class includes the ``\verb|booktabs|''
package --- \url{https://ctan.org/pkg/booktabs} --- for preparing
high-quality tables.

Table captions are placed {\itshape above} the table.

Because tables cannot be split across pages, the best placement for
them is typically the top of the page nearest their initial cite.  To
ensure this proper ``floating'' placement of tables, use the
environment \textbf{table} to enclose the table's contents and the
table caption.  The contents of the table itself must go in the
\textbf{tabular} environment, to be aligned properly in rows and
columns, with the desired horizontal and vertical rules.  Again,
detailed instructions on \textbf{tabular} material are found in the
\textit{\LaTeX\ User's Guide}.

Immediately following this sentence is the point at which
Table~\ref{tab:freq} is included in the input file; compare the
placement of the table here with the table in the printed output of
this document.

\begin{table}
  \caption{Frequency of Special Characters}
  \label{tab:freq}
  \begin{tabular}{ccl}
    \toprule
    Non-English or Math&Frequency&Comments\\
    \midrule
    \O & 1 in 1,000& For Swedish names\\
    $\pi$ & 1 in 5& Common in math\\
    \$ & 4 in 5 & Used in business\\
    $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
  \bottomrule
\end{tabular}
\end{table}

To set a wider table, which takes up the whole width of the page's
live area, use the environment \textbf{table*} to enclose the table's
contents and the table caption.  As with a single-column table, this
wide table will ``float'' to a location deemed more
desirable. Immediately following this sentence is the point at which
Table~\ref{tab:commands} is included in the input file; again, it is
instructive to compare the placement of the table here with the table
in the printed output of this document.

\begin{table*}
  \caption{Some Typical Commands}
  \label{tab:commands}
  \begin{tabular}{ccl}
    \toprule
    Command &A Number & Comments\\
    \midrule
    \texttt{{\char'134}author} & 100& Author \\
    \texttt{{\char'134}table}& 300 & For tables\\
    \texttt{{\char'134}table*}& 400& For wider tables\\
    \bottomrule
  \end{tabular}
\end{table*}

Always use midrule to separate table header rows from data rows, and
use it only for this purpose. This enables assistive technologies to
recognise table headers and support their users in navigating tables
more easily.

\section{Math Equations}
You may want to display math equations in three distinct styles:
inline, numbered or non-numbered display.  Each of the three are
discussed in the next sections.

\subsection{Inline (In-text) Equations}
A formula that appears in the running text is called an inline or
in-text formula.  It is produced by the \textbf{math} environment,
which can be invoked with the usual
\texttt{{\char'134}begin\,\ldots{\char'134}end} construction or with
the short form \texttt{\$\,\ldots\$}. You can use any of the symbols
and structures, from $\alpha$ to $\omega$, available in
\LaTeX~\cite{Lamport:LaTeX}; this section will simply show a few
examples of in-text equations in context. Notice how this equation:
\begin{math}
  \lim_{n\rightarrow \infty}x=0
\end{math},
set here in in-line math style, looks slightly different when
set in display style.  (See next section).

\subsection{Display Equations}
A numbered display equation---one set off by vertical space from the
text and centered horizontally---is produced by the \textbf{equation}
environment. An unnumbered display equation is produced by the
\textbf{displaymath} environment.

Again, in either environment, you can use any of the symbols and
structures available in \LaTeX\@; this section will just give a couple
of examples of display equations in context.  First, consider the
equation, shown as an inline equation above:
\begin{equation}
  \lim_{n\rightarrow \infty}x=0
\end{equation}
Notice how it is formatted somewhat differently in
the \textbf{displaymath}
environment.  Now, we'll enter an unnumbered equation:
\begin{displaymath}
  \sum_{i=0}^{\infty} x + 1
\end{displaymath}
and follow it with another numbered equation:
\begin{equation}
  \sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f
\end{equation}
just to demonstrate \LaTeX's able handling of numbering.

\section{Figures}

The ``\verb|figure|'' environment should be used for figures. One or
more images can be placed within a figure. If your figure contains
third-party material, you must clearly identify it as such, as shown
in the example below.
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{sample-franklin}
  \caption{1907 Franklin Model D roadster. Photograph by Harris \&
    Ewing, Inc. [Public domain], via Wikimedia
    Commons. (\url{https://goo.gl/VLCRBB}).}
  \Description{A woman and a girl in white dresses sit in an open car.}
\end{figure}

Your figures should contain a caption which describes the figure to
the reader.

Figure captions are placed {\itshape below} the figure.

Every figure should also have a figure description unless it is purely
decorative. These descriptions convey what’s in the image to someone
who cannot see it. They are also used by search engine crawlers for
indexing images, and when images cannot be loaded.

A figure description must be unformatted plain text less than 2000
characters long (including spaces).  {\bfseries Figure descriptions
  should not repeat the figure caption – their purpose is to capture
  important information that is not already provided in the caption or
  the main text of the paper.} For figures that convey important and
complex new information, a short text description may not be
adequate. More complex alternative descriptions can be placed in an
appendix and referenced in a short figure description. For example,
provide a data table capturing the information in a bar chart, or a
structured list representing a graph.  For additional information
regarding how best to write figure descriptions and why doing this is
so important, please see
\url{https://www.acm.org/publications/taps/describing-figures/}.

\subsection{The ``Teaser Figure''}

A ``teaser figure'' is an image, or set of images in one figure, that
are placed after all author and affiliation information, and before
the body of the article, spanning the page. If you wish to have such a
figure in your article, place the command immediately before the
\verb|\maketitle| command:
\begin{verbatim}
  \begin{teaserfigure}
    \includegraphics[width=\textwidth]{sampleteaser}
    \caption{figure caption}
    \Description{figure description}
  \end{teaserfigure}
\end{verbatim}

\section{Citations and Bibliographies}

The use of \BibTeX\ for the preparation and formatting of one's
references is strongly recommended. Authors' names should be complete
--- use full first names (``Donald E. Knuth'') not initials
(``D. E. Knuth'') --- and the salient identifying features of a
reference should be included: title, year, volume, number, pages,
article DOI, etc.

The bibliography is included in your source document with these two
commands, placed just before the \verb|\end{document}| command:
\begin{verbatim}
  \bibliographystyle{ACM-Reference-Format}
  \bibliography{bibfile}
\end{verbatim}
where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
suffix, of the \BibTeX\ file.

Citations and references are numbered by default. A small number of
ACM publications have citations and references formatted in the
``author year'' style; for these exceptions, please include this
command in the {\bfseries preamble} (before the command
``\verb|\begin{document}|'') of your \LaTeX\ source:
\begin{verbatim}
  \citestyle{acmauthoryear}
\end{verbatim}


  Some examples.  A paginated journal article \cite{Abril07}, an
  enumerated journal article \cite{Cohen07}, a reference to an entire
  issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
  monograph/whole book in a series (see 2a in spec. document)
  \cite{Harel79}, a divisible-book such as an anthology or compilation
  \cite{Editor00} followed by the same example, however we only output
  the series if the volume number is given \cite{Editor00a} (so
  Editor00a's series should NOT be present since it has no vol. no.),
  a chapter in a divisible book \cite{Spector90}, a chapter in a
  divisible book in a series \cite{Douglass98}, a multi-volume work as
  book \cite{Knuth97}, a couple of articles in a proceedings (of a
  conference, symposium, workshop for example) (paginated proceedings
  article) \cite{Andler79, Hagerup1993}, a proceedings article with
  all possible elements \cite{Smith10}, an example of an enumerated
  proceedings article \cite{VanGundy07}, an informally published work
  \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
    AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
  master's thesis: \cite{anisi03}, an online document / world wide web
  resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
  (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
  and (Case 3) a patent \cite{JoeScientist001}, work accepted for
  publication \cite{rous08}, 'YYYYb'-test for prolific author
  \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
  contain 'duplicate' DOI and URLs (some SIAM articles)
  \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
  multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
  presentation~\cite{Reiser2014}. An article under
  review~\cite{Baggett2025}. A
  couple of citations with DOIs:
  \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
  citations: \cite{TUGInstmem, Thornburg01, CTANacmart}.
  Artifacts: \cite{R} and \cite{UMassCitations}.

\section{Acknowledgments}

Identification of funding sources and other support, and thanks to
individuals and groups that assisted in the research and the
preparation of the work should be included in an acknowledgment
section, which is placed just before the reference section in your
document.

This section has a special environment:
\begin{verbatim}
  \begin{acks}
  ...
  \end{acks}
\end{verbatim}
so that the information contained therein can be more easily collected
during the article metadata extraction phase, and to ensure
consistency in the spelling of the section heading.

Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.

\section{Appendices}

If your work needs an appendix, add it before the
``\verb|\end{document}|'' command at the conclusion of your source
document.

Start the appendix with the ``\verb|appendix|'' command:
\begin{verbatim}
  \appendix
\end{verbatim}
and note that in the appendix, sections are lettered, not
numbered. This document has two appendices, demonstrating the section
and subsection identification method.

\section{Multi-language papers}

Papers may be written in languages other than English or include
titles, subtitles, keywords and abstracts in different languages (as a
rule, a paper in a language other than English should include an
English title and an English abstract).  Use \verb|language=...| for
every language used in the paper.  The last language indicated is the
main language of the paper.  For example, a French paper with
additional titles and abstracts in English and German may start with
the following command
\begin{verbatim}
\documentclass[sigconf, language=english, language=german,
               language=french]{acmart}
\end{verbatim}

The title, subtitle, keywords and abstract will be typeset in the main
language of the paper.  The commands \verb|\translatedXXX|, \verb|XXX|
begin title, subtitle and keywords, can be used to set these elements
in the other languages.  The environment \verb|translatedabstract| is
used to set the translation of the abstract.  These commands and
environment have a mandatory first argument: the language of the
second argument.  See \verb|sample-sigconf-i13n.tex| file for examples
of their usage.

\section{SIGCHI Extended Abstracts}

The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
not in Word) produces a landscape-orientation formatted article, with
a wide left margin. Three environments are available for use with the
``\verb|sigchi-a|'' template style, and produce formatted output in
the margin:
\begin{description}
\item[\texttt{sidebar}:]  Place formatted text in the margin.
\item[\texttt{marginfigure}:] Place a figure in the margin.
\item[\texttt{margintable}:] Place a table in the margin.
\end{description}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
To Robert, for the bagels and explaining CMYK and color spaces.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Research Methods}

\subsection{Part One}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
lacinia dolor. Integer ultricies commodo sem nec semper.

\subsection{Part Two}

Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
eros. Vivamus non purus placerat, scelerisque diam eu, cursus
ante. Etiam aliquam tortor auctor efficitur mattis.

\section{Online Resources}

Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
enim maximus. Vestibulum gravida massa ut felis suscipit
congue. Quisque mattis elit a risus ultrices commodo venenatis eget
dui. Etiam sagittis eleifend elementum.

Nam interdum magna at lectus dignissim, ac dignissim lorem
rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
